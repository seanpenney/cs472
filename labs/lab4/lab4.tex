\documentclass[letterpaper,12pt,titlepage]{article}

\usepackage{graphicx}                                        
\usepackage{amssymb}                                         
\usepackage{amsmath}                                         
\usepackage{amsthm}                                          

\usepackage{alltt}                                           
\usepackage{float}
\usepackage{color}
\usepackage{url}

\usepackage{balance}
\usepackage[TABBOTCAP, tight]{subfigure}
\usepackage{enumitem}
\usepackage{pstricks, pst-node}

\usepackage{geometry}
\geometry{textheight=9in, textwidth=6.5in}

\newcommand{\cred}[1]{{\color{red}#1}}
\newcommand{\cblue}[1]{{\color{blue}#1}}

\usepackage{hyperref}
\usepackage{geometry}

\usepackage{listings}


\def\name{Sean Penney and Paul Atkinson}

%% The following metadata will show up in the PDF properties
\hypersetup{
  colorlinks = true,
  urlcolor = black,
  pdfauthor = {\name},
  pdfkeywords = {cs472 ``computer architecture'' clements ``chapter 9''},
  pdftitle = {CS 472: Lab 4},
  pdfsubject = {CS 472: Lab 4},
  pdfpagemode = UseNone
}

\begin{document}
\hfill \name

\hfill \today

\hfill CS 472 Lab 4


\centerline{\large Memory Optimization}
 
 
The memory operation paper talks about practices to improve memory optimization, both in general and in more specific cercumstances.
\newline
\par
The paper starts with why memory optimization is actually necessary. It is necessary because memory technology is progressing at a very
slow pace when compared to how much CPUs are getting better. Thus, memory optimization is needed so our applications aren't bottlenecked 
by the memory rather then the processor. Moreover, there are a lot of easy practices you can develop that subtely help the run time of 
applications.
\newline
\par
There are three main ways of optimizing code: rearranging, reducing and reusing. Rearranging is when you have variables that are accessed 
at the same time, you should have the variables declared next to each other. Reducing is reducing the amount of code to run, which obviously 
makes it more efficent. However, sometimes something that looks like less code in C is actually more lines of machine code, so it doesn't 
actually save time. In these curcumstances, you want to compile the code and then analyze it to see if there are some ways of shorting 
the amount of code that needs to be run. The final R is reusing, which means reusing as much code as possible so the program doesn't have 
to load in more then it has to. This usually means making functions if you have to do the same thing more then once.
\newline
\par
There are also three main ways of screwing up the cache: compulsory misses, capacity misses and conflict misses. Compulsory misses are 
the first miss that happens when the data is read for the first time. While these are inevitible, it is good practice to avoid these as 
possible. Capacity misses don't happen quite as much anymore, but it is when the cache is too small to hold all the active data you want 
to hold. Sometimes you can hit capacity if you are accessing too much data inbetween successive uses. Conflict misses happen when you have 
two things that are mapped to the same line in cache.
\newline
\par
Software prefetching and preloading can also help speed up memory operations. However, if you fetch too early, the data can take up 
unnecessary space or may be evicted from the memory before it is ever actually used. If the memory is fetched too late, then everything 
will be bottlenecked by it loading. Preloading is sort of the same as prefetching, however it isn't sure what is going to be needed 
so it guesses. Sometimes it guesses wrong and it ends up wasting time loading in the correct thing, but overall it usually saves more 
time then it loses.
\newline
\newline
\newpage

\centerline{\large What Every Programmer Should Know About Memory}
This paper introduces starts by introducing why caching is important.  Since mass storage and memory systems have improved slowly compared
to the CPU and other component, the memory creates the bottleneck in a system.
\newline
\par
Current hardware is discussed, focusing on CPUs and RAM types.  A CPU is connected via a bus to the Northbridge which contains the memory controller.
The implementation of the Northbridge effects the type of RAM chips that can be used (DRAM, Rambus, SDRAM, etc).  The Southbridge communicates with
PCI, PCI Express, SATA, USB buses, etc.  Sometimes the Northbridge is connected to other controllers, which allows more memory since there is more
total available bandwidth.
\newline
\par
An Overview of RAM types are given, focusing on Static RAM and Dynamic RAM.  SRAM is much more expensive, and use is CPU caches where the connections
are small.  The coast of the memory controller, motherboard, DRAM module, and DRAM chip is based on the number of address lines.  Another memory technology
is Synchronous DRAM, which works relative to a time source.
\newline
\par
The paper next goes into more detail about the cache, and techniques for using it.  All loads and stores have to go through the cache, so the connection
between the CPU core and the cache is specialized and fast.  One technique that helps with the efficiency of the cache is using sepate code and data caches.
The memory regions needed for code and data are different, which logically leads to different caches.  Also, the decoding step is usually slow, so 
caching decoded instructions can speed up execution.  These days more levels of cache have been added, since increasing the size of the level 1 cache
led to much greater costs.
\newline
\par
Caches can be implemented in different ways.  A fully associative cache allows for each cache line to hold a copy of any memory location.

\end{document}
