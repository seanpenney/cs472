\documentclass[letterpaper,10pt,titlepage]{article}

\usepackage{graphicx}                                        
\usepackage{amssymb}                                         
\usepackage{amsmath}                                         
\usepackage{amsthm}                                          

\usepackage{alltt}                                           
\usepackage{float}
\usepackage{color}
\usepackage{url}

\usepackage{balance}
\usepackage[TABBOTCAP, tight]{subfigure}
\usepackage{enumitem}
\usepackage{pstricks, pst-node}

\usepackage{geometry}
\geometry{textheight=9in, textwidth=6.5in}

\newcommand{\cred}[1]{{\color{red}#1}}
\newcommand{\cblue}[1]{{\color{blue}#1}}

\usepackage{hyperref}
\usepackage{geometry}

\usepackage{listings}


\def\name{Sean Penney and Paul Atkinson}

%% The following metadata will show up in the PDF properties
\hypersetup{
  colorlinks = true,
  urlcolor = black,
  pdfauthor = {\name},
  pdfkeywords = {cs472 ``computer architecture'' clements ``chapter 9''},
  pdftitle = {CS 472: Homework 5},
  pdfsubject = {CS 472: Homework 5},
  pdfpagemode = UseNone
}

\begin{document}
\hfill \name

\hfill \today

\hfill CS 472 HW 5

\begin{enumerate}
\item[$(9.2)$] 

  The cache speeds up memory access by storing more frequently accessed data in the cache, rather than the slower main memory.

\item[$(9.3)$]

  Temporal locality refers to reusing specific data in a small amount of time, and spatial locality refers to reusing data that is grouped together.    

\item[$(9.4)$]

  S = t_{m} / (h * t_{c} + (1 - h)t_{m}), where t_{m} is access time of main memory, t_{c} is the access time of cache memory, and h is the hit ratio.
 
  This formula simplifies to:
 
  S = 1 / (1 - h(1 - k)), where k is the ratio of the access time to cache memory divided by the access time to main memory.
  
\item[$(9.5)$]
  
  a.  S = 526.3%
 
  b.  S = 689.6%
 
  c.  S = 416.67%
 
  d.  S = 1273.89%
  
\item[$(9.6)$]

  a.  h = .0957
 
  b.  h = .5263
 
  c.  h = .8421
 
  d.  h = .9825

\item[$(9.8)$]
  
  t_{m} / t_{c} ??
  
\item[$(9.11)$]   
  
  a.  Word is a unit of data
  
  b.  A line is made up of individual words.
  
  c.  A set is a group of lines??
  
\item[$(9.12)$]
  
  a.  Using direct mapped cache, the data is stored like a simple table, with columns for data and tags.
 
  b.  A fully associative cache allows you to store the data anywhere in the cache.

  c.  A set-associative cache is a hybrid between a fully associative and direct mapped cache.  There is a general location in which the data is to be stored, and within that general location the data can be stored anywhere.
  
\item[$(9.17)$]

  Cache coherency refers to whether the data is consistent.  Write operations should occur instantaneously, processors should see the same sequence of changes of values, etc.
  
\item[$(9.22)$]

  Data caches are easier to implement than instruction caches since the contents of data caches are not modified.

\item[$(9.23)$]

  The average access time of a system with a cache that's accessed in parallel with main store is t_{ave} = ht_{c} + (1-h)t_{m}
  
  Let t_{1} be the time to fetch a line from main store to reload the cache on a miss.  We must add (1-h)t_{1} to the average access time.
  
  t_{ave} = ht_{c} + (1-h)t_{m} + (1-h)t_{1}

\item[$(9.26)$]

\item[$(9.28)$]

  The local miss rate is the number of misses in a specific cache divided by the total number of memory accesses to this cache.
  
  The global miss rate is the misses in a specific cache divided by the total number of memory accesses by the CPU.

\item[$(9.35)$]

\item[$(9.41)$]

  CPU cache is a portion of memory made of high-speed static RAM.
  
  Disk caching uses same principles as CPU caches, however, disk caching uses conventional main memory instead of SRAM.

\item[$(9.42)$]

\item[$(9.43)$]

  

\item[$(9.45)$]

\item[$(9.46)$]

\item[$(9.57)$]
  
\begin{lstlisting}
\end{lstlisting}
  
\end{enumerate}



\end{document}
